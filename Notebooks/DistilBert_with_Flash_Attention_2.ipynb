{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FdgvAMLNVTi"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -U\n",
        "!pip install accelerate -U\n",
        "!pip install -U flash-attn --no-build-isolation #install flash attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import time"
      ],
      "metadata": {
        "id": "beVuWVwINeDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "java_file_path = '/content/drive/MyDrive/Wajid Ali/FYP/Dataset/java.csv'\n",
        "python_file_path = '/content/drive/MyDrive/Wajid Ali/FYP/Dataset/python.csv'\n",
        "pharo_file_path = '/content/drive/MyDrive/Wajid Ali/FYP/Dataset/pharo.csv'\n",
        "java_df = pd.read_csv(java_file_path)\n",
        "python_df = pd.read_csv(python_file_path)\n",
        "pharo_df = pd.read_csv(pharo_file_path)"
      ],
      "metadata": {
        "id": "QyxiJR3yNhSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "java_df['category'] = java_df['category'].replace('Expand', 'java_Expand')\n",
        "df = pd.concat([java_df, python_df, pharo_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "7c2Tv0OINjTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing of the dataset\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "XFn-FYChOTak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove extra spaces while allowing all characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "dJXMODSsOUjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combo'] = df['class'] + \" \" + df['comment_sentence']\n",
        "df['combo'] = df['combo'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "_YtbJMUuOX0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing data\n",
        "train_data = df[df['partition'] == 1]\n",
        "test_data = df[df['partition'] == 0]"
      ],
      "metadata": {
        "id": "jZL8otT4OZuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Dataset preparation\n",
        "device = \"cuda\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").to(device)\n"
      ],
      "metadata": {
        "id": "WxLUGwWJOb1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CommentDataset(Dataset):\n",
        "    def __init__(self, combos, labels, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.combos = combos\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.combos)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        combo = str(self.combos[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            combo,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "Es2UTmirOezN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CommentDataset(train_data['combo'].to_numpy(), train_data['category'].astype('category').cat.codes.to_numpy(), tokenizer)\n",
        "test_dataset = CommentDataset(test_data['combo'].to_numpy(), test_data['category'].astype('category').cat.codes.to_numpy(), tokenizer)"
      ],
      "metadata": {
        "id": "6IrJ_Cs2Ojt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps'\n",
        ")"
      ],
      "metadata": {
        "id": "0Nho8bn5OkaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "K6AAcs9UOpBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "beMSIcy5Oq8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "DvUpAhG6Os7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIDOLIc6Os5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}